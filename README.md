# ğŸš¨ DetecÃ§Ã£o de Fraude em CartÃ£o de CrÃ©dito
## Tech Challenge Fase 3 - FIAP

Sistema completo de **Machine Learning para detecÃ§Ã£o de fraude** com pipeline modular, PostgreSQL para persistÃªncia e CLI interativo.

---

## ğŸ† Modelo Final

**Quando usar**: Primeira vez ou apÃ³s mudanÃ§as no dataset original.

---

### Modo 1: Train (Treinamento RÃ¡pido)t v2.1.0** - Modelo otimizado em produÃ§Ã£o:

| MÃ©trica | Valor | BenefÃ­cio |
|---------|-------|-----------|
| **PR-AUC** | 0.8772 | MÃ©trica robusta para desbalanceamento |
| **Precision** | 86.60% | 86% das prediÃ§Ãµes de fraude estÃ£o corretas |
| **Recall** | 81.63% | Detecta 82% das fraudes reais |
| **F1-Score** | 84.04% | EquilÃ­brio entre Precision e Recall |
| **Falsos Positivos** | 13 | Apenas R$ 260/dia de custo operacional |
| **Features** | 33 | Modelo enxuto e rÃ¡pido (11% reduÃ§Ã£o) |

**Dataset**: creditcard.csv (Kaggle) - 284.807 transaÃ§Ãµes, 492 fraudes (0.172%)

---

## ğŸ¯ Objetivo

Desenvolver sistema de detecÃ§Ã£o de fraude usando **XGBoost otimizado** com:
- âœ… Tratamento de dados **altamente desbalanceados** (ratio 1:578)
- âœ… Pipeline modular MVC-ML (processamento â†’ treinamento â†’ inferÃªncia)
- âœ… ValidaÃ§Ã£o robusta com **StratifiedKFold**
- âœ… **Grid Search automatizado** com versionamento de hiperparÃ¢metros
- âœ… **PostgreSQL** (dados) + **Pickle** (modelos) para rastreabilidade
- âœ… **CLI completo** (pipeline/train/tune/predict) com 4 modos de operaÃ§Ã£o
---

## ğŸ—ï¸ Arquitetura do Projeto

### Estrutura MVC-ML Modular
```
src/ml/
â”œâ”€â”€ processing/           # ğŸ”§ FunÃ§Ãµes reutilizÃ¡veis (OTIMIZADAS!)
â”‚   â”œâ”€â”€ loader.py         # PostgreSQL COPY (81.6% mais rÃ¡pido)
â”‚   â”œâ”€â”€ validation.py     # Schema e integridade
â”‚   â”œâ”€â”€ cleaning.py       # AnÃ¡lise de outliers (preserva 100%)
â”‚   â”œâ”€â”€ normalization.py  # RobustScaler + StandardScaler
â”‚   â”œâ”€â”€ feature_engineering.py  # 9 novas features
â”‚   â”œâ”€â”€ feature_selection.py    # AnÃ¡lise automatizada
â”‚   â”œâ”€â”€ splitters.py      # Stratified train/test split
â”‚   â””â”€â”€ metadata.py       # Pipeline metadata tracking
â”‚
â”œâ”€â”€ pipelines/            # ğŸš€ Encadeamento de processos
â”‚   â””â”€â”€ data_pipeline.py  # Steps 01-07 (completo, 52% mais rÃ¡pido)
â”‚
â”œâ”€â”€ training/             # ğŸ“ Scripts de treinamento ML
â”‚   â”œâ”€â”€ train.py          # â­ Treino com hiperparÃ¢metros do JSON
â”‚   â””â”€â”€ tune.py           # â­ Grid Search + atualizaÃ§Ã£o automÃ¡tica de JSON
â”‚
â””â”€â”€ models/               # âš™ï¸ ConfiguraÃ§Ãµes centralizadas
    â””â”€â”€ configs.py        # Dataclasses tipadas + carregamento de JSON
```

### Pipeline de Dados (7 Steps - 52% mais rÃ¡pido âš¡)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DATA PROCESSING PIPELINE (~62s)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  CSV Raw (284,807) â†’ [01] Load Raw â†’ PostgreSQL (raw_transactions)  â”‚
â”‚                         â†“ (~20s)                                     â”‚
â”‚                    [02] Outlier Analysis â†’ Metadata only             â”‚
â”‚                         â†“ (paralelo ~2.4s)                          â”‚
â”‚                    [03] Missing Values â†’ Metadata only               â”‚
â”‚                         â†“ (paralelo ~2.4s)                          â”‚
â”‚                    [04] Normalize â†’ PostgreSQL + scalers.pkl         â”‚
â”‚                         â†“ (~16.5s - OTIMIZADO 81.6% ğŸ”¥)             â”‚
â”‚                    [05] Feature Engineering â†’ PostgreSQL (40 cols)   â”‚
â”‚                         â†“ (~20.6s - Time_Period, Amount_Log, stats) â”‚
â”‚                    [05.5] Feature Selection Analysis â†’ JSON Report   â”‚
â”‚                         â†“ (~15s - Pearson, Spearman, MI, VIF)       â”‚
â”‚                    [06] Apply Feature Selection â†’ PostgreSQL (33)    â”‚
â”‚                         â†“ (~5s - Config-driven removal)             â”‚
â”‚                    [07] Train/Test Split â†’ train_data + test_data    â”‚
â”‚                         â†“ (~22.2s - StratifiedKFold 80/20)          â”‚
â”‚                                                                      â”‚
â”‚  TOTAL: ~62s (antes: ~130s) - GANHO: 52% âš¡                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Arquitetura de PersistÃªncia

**PostgreSQL - Tabelas do Pipeline**:
- `raw_transactions` (284,807 linhas): CSV original
- `cleaned_transactions` (284,804 linhas): Sem outliers
- `imputed_transactions` (284,804 linhas): Sem missing values
- `normalized_transactions` (284,804 linhas): Features normalizadas
- `engineered_transactions` (284,804 linhas): Features novas (40 colunas)
- `train_features` (~227,843 linhas): 80% treino
- `test_features` (~56,961 linhas): 20% teste

**PostgreSQL - Tabelas de Metadados** (ğŸ”® FUTURO - nÃ£o implementadas):
- `metrics_history`: MÃ©tricas de modelos ao longo do tempo
- `trained_models`: Registro de modelos treinados com timestamps
- `data_splits`: HistÃ³rico de splits train/test

**Pickle (modelos ML)**:
- `models/scalers.pkl`: RobustScaler + StandardScaler (fit em train)
- `models/xgboost_v2.1.0.pkl`: Modelo final em produÃ§Ã£o â­

**JSON (hiperparÃ¢metros versionados)**:
- `data/xgboost_hyperparameters.json`: HiperparÃ¢metros ativos
- `data/archive/`: VersÃµes anteriores com timestamp automÃ¡tico

**Por que hÃ­brido?**
- **PostgreSQL**: Rastreabilidade, SQL analytics, backups automÃ¡ticos
- **Pickle**: Fast loading (~0.1s), mÃ©todos do objeto preservados, scikit-learn nativo
- **JSON**: Versionamento de hiperparÃ¢metros, comparaÃ§Ãµes dinÃ¢micas, production-ready

### Stack TecnolÃ³gico
- **Data Pipeline**: Python 3.13 + Pandas + PostgreSQL 15
- **ML Model**: XGBoost 3.0.5 (scale_pos_weight=577, max_depth=6)
- **PersistÃªncia**: PostgreSQL (dados) + Pickle (modelos)
- **OtimizaÃ§Ã£o**: PostgreSQL COPY, ThreadPoolExecutor, metadata-only steps
- **Infraestrutura**: Docker Compose (PostgreSQL)

---

## ğŸ“Š Dataset

- **Fonte**: Kaggle - Credit Card Fraud Detection
- **TransaÃ§Ãµes**: 284.807 (2 dias, setembro 2013)
- **Features**: 30 (Time, Amount, V1-V28 via PCA)
- **Target**: Class (0=legÃ­tima, 1=fraude)
- **Desbalanceamento**: 492 fraudes (0.172%) vs 284.315 legÃ­timas

---

## ğŸš€ Quick Start

### 1. PrÃ©-requisitos
- Python 3.13+
- PostgreSQL 15+ (ou Docker)
- 2GB+ RAM disponÃ­vel

### 2. InstalaÃ§Ã£o

```bash
# Clone do repositÃ³rio
git clone <repo-url>
cd ml-fraud-detector

# Criar ambiente virtual
python3 -m venv .venv
source .venv/bin/activate  # Linux/Mac
# .venv\Scripts\activate   # Windows

# Instalar dependÃªncias
pip install -r requirements.txt

# OU usando uv (mais rÃ¡pido)
uv pip install -e .
```

### 3. Configurar PostgreSQL

**OpÃ§Ã£o A: Docker (Recomendado)**
```bash
cd database
docker-compose up -d

# Validar conexÃ£o
docker exec -it fraud_detection_postgres psql -U fraud_user -d fraud_detection -c "\dt"
```

**OpÃ§Ã£o B: PostgreSQL Local**
```bash
# Criar banco e usuÃ¡rio
createdb fraud_detection
createuser fraud_user --password fraud_pass_dev

# Aplicar schema
psql -U fraud_user -d fraud_detection -f database/schema.sql
```

### 4. Executar Pipeline de Dados

```bash
# OpÃ§Ã£o 1: Via CLI (RECOMENDADO)
python main.py pipeline

# OpÃ§Ã£o 2: Direto (legacy)
python -m src.ml.pipelines.data_pipeline

# Resultado esperado (~62s):
# âœ… raw_transactions: 284,807 linhas
# âœ… cleaned_transactions: 284,804 linhas (outliers removidos)
# âœ… imputed_transactions: 284,804 linhas (missing tratados)
# âœ… normalized_transactions: 284,804 linhas (RobustScaler aplicado)
# âœ… engineered_transactions: 284,804 linhas (40 features)
# âœ… train_features: ~227,843 linhas (394 fraudes)
# âœ… test_features: ~56,961 linhas (98 fraudes)
# âœ… scalers.pkl salvo em models/
```

---

## ğŸ–¥ï¸ CLI Principal (`main.py`)

O projeto inclui um **CLI completo** com 4 modos de operaÃ§Ã£o:

### Modo 1: Pipeline (Processamento de Dados)

Executa pipeline completo de dados (Steps 01-07, ~62s):

```bash
# Pipeline completo
python main.py pipeline

# SaÃ­da esperada:
# ğŸš€ MODO: PIPELINE DE DADOS
# Data: 2025-10-03 14:35:22
# â±ï¸  Tempo estimado: ~62 segundos
# 
# ğŸš€ Executando pipeline completo...
#    Script: data_pipeline.py
#    Steps: 01-07
# 
# âœ… Pipeline completo!
# ğŸ“Š Resultado esperado:
#    âœ… raw_transactions: 284,807 linhas
#    âœ… cleaned_transactions: 284,804 linhas
#    âœ… imputed_transactions: 284,804 linhas
#    âœ… normalized_transactions: 284,804 linhas
#    âœ… engineered_transactions: 284,804 linhas (40 features)
#    âœ… train_features: ~227,843 linhas (394 fraudes)
#    âœ… test_features: ~56,961 linhas (98 fraudes)
#    âœ… scalers.pkl salvo em models/
# 
# ğŸ’¡ PrÃ³ximo passo: python main.py train
```

**Quando usar**: Primeira vez ou apÃ³s mudanÃ§as no dataset original.
 


### Modo 2: Train (Treinamento RÃ¡pido)

Treina modelo usando hiperparÃ¢metros de `data/xgboost_hyperparameters.json` (~1 min):

```bash
# Treinar XGBoost com JSON ativo (assume dados jÃ¡ no PostgreSQL)
python main.py train

# Especificar versÃ£o personalizada
python main.py train --model-version 2.1.1

# Overwrite modelo existente (move antigo para models/archive/)
python main.py train --model-version 2.1.0 -ow

# SaÃ­da esperada:
# ğŸš€ MODO: TREINAMENTO
# âœ… Train: 227,845 linhas (394 fraudes)
# âœ… Test: 56,962 linhas (98 fraudes)
# ğŸ“Š Cross-Validation (StratifiedKFold k=5)...
#    Precision (CV): 0.8123 Â± 0.0234
#    Recall (CV): 0.8456 Â± 0.0189
# âœ… Modelo salvo: models/xgboost_v2.1.0.pkl
#    PR-AUC: 0.8772
#    Precision: 86.60%
#    False Positives: 13
```

**Versionamento AutomÃ¡tico:**
- **Sem `-ow`**: Salva em `models/archive/xgboost_v{version}_{timestamp}.pkl`
- **Com `-ow`**: Move modelo antigo para archive e cria novo em `models/`

**Quando usar**: Treinar rapidamente com parÃ¢metros conhecidos bons (JSON ativo).

---

### Modo 3: Tune (Grid Search AutomÃ¡tico)

Executa **Grid Search** (~20 min) e **atualiza `data/xgboost_hyperparameters.json`** automaticamente:

```bash
# Grid Search (modo archive - padrÃ£o)
python main.py tune

# Grid Search + overwrite do JSON ativo
python main.py tune -ow

# Especificar versÃ£o otimizada
python main.py tune --model-version 3.0.0 -ow

# SaÃ­da esperada:
# ğŸ”§ MODO: TUNING (Grid Search)
# âš ï¸  ATENÃ‡ÃƒO: Grid Search pode levar ~20 minutos
# âœ… Train: 227,845 linhas
# 
# ğŸ“Œ VersÃµes anteriores disponÃ­veis:
#    âœ… v2.0.0: PR-AUC 0.8847, Precision 85.42%, FP 14, Features 37
#       v1.1.0: PR-AUC 0.8719, Precision 72.27%, FP 33, Features 37
# 
# ğŸ”§ Executando Grid Search...
#    CombinaÃ§Ãµes: 729 (3Ã—3Ã—3Ã—3Ã—3Ã—3Ã—1)
#    CV: StratifiedKFold k=3
#    Total fits: 2,187
# âœ… Grid Search completo!
# ğŸ† Melhores ParÃ¢metros:
#    colsample_bytree: 0.7
#    learning_rate: 0.3
#    max_depth: 6
#    ...
#    PR-AUC: 0.8772
# 
# ï¿½ Atualizando configs.py com melhores hiperparÃ¢metros...
#    Backup criado: configs_backup_20251003_143522.py
#    âœ… configs.py atualizado!
```

**Quando usar**: 
- Otimizar hiperparÃ¢metros apÃ³s mudanÃ§as no dataset (novas features, etc.)
- Experimentar novos grids de busca

**SeguranÃ§a**:
- Cria **backup automÃ¡tico** de `configs.py` antes de atualizar
- Modo `--auto-update` para pipelines CI/CD
- Modo interativo pede confirmaÃ§Ã£o antes de atualizar

---

### Modo 4: Predict (InferÃªncia)

Executa prediÃ§Ãµes em **CSV** ou **JSON**:

**OpÃ§Ã£o A: CSV**
```bash
python main.py predict --file data/new_transactions.csv

# SaÃ­da esperada:
# ğŸ”® MODO: PREDIÃ‡ÃƒO (CSV)
# ğŸ“¥ Carregando modelo: xgboost_v2.1.0.pkl
# âœ… 1,000 transaÃ§Ãµes carregadas
# âœ… PrediÃ§Ãµes completas!
# ğŸ“Š Resumo:
#    Total transaÃ§Ãµes: 1,000
#    Fraudes detectadas: 3 (0.30%)
#    LegÃ­timas: 997
# ğŸ’¾ Resultados salvos: data/new_transactions_predictions.csv
#
# âš ï¸  Top 5 Fraudes com Maior Probabilidade:
#    Linha 42: 95.23% probabilidade
#    Linha 157: 89.45% probabilidade
#    Linha 891: 78.12% probabilidade
```

**OpÃ§Ã£o B: JSON (arquivo)**
```bash
python main.py predict --json-file input.json

# input.json exemplo:
# [
#   {"V1": -0.5, "V2": 1.2, "V3": 0.8, ..., "Amount_Log": 4.5},
#   {"V1": 0.3, "V2": -0.9, "V3": 1.1, ..., "Amount_Log": 3.2}
# ]

# SaÃ­da:
# ğŸ”® MODO: PREDIÃ‡ÃƒO (JSON)
# âœ… 2 transaÃ§Ãµes carregadas
# ğŸ“‹ Resultados:
#    ğŸš¨ TransaÃ§Ã£o 0: FRAUDE (95.23%)
#    âœ… TransaÃ§Ã£o 1: LEGÃTIMA (2.45%)
# ğŸ’¾ Resultados salvos: prediction_results.json
```

**OpÃ§Ã£o C: JSON (inline)**
```bash
python main.py predict --json '{"V1": -0.5, "V2": 1.2, "V3": 0.8, "Amount_Log": 4.5}'

# SaÃ­da:
# ğŸ”® MODO: PREDIÃ‡ÃƒO (JSON)
# âœ… 1 transaÃ§Ã£o carregada
# ğŸ“‹ Resultados:
#    ğŸš¨ TransaÃ§Ã£o 0: FRAUDE (89.34%)
```

**Quando usar**:
- **CSV**: Batch processing de muitas transaÃ§Ãµes
- **JSON file**: IntegraÃ§Ã£o com APIs/sistemas externos
- **JSON inline**: Testes rÃ¡pidos, CI/CD pipelines

---

## ğŸ“š DocumentaÃ§Ã£o Completa

### Planos EstratÃ©gicos
- **`docs/plan_main.md`**: Plano MVP completo com XGBoost v1.1.0, v2.0.0, v2.1.0
- **`docs/plan_kafka.md`**: Enhancement Kafka (opcional, nÃ£o implementado)
- **`docs/changelog.md`**: Registro de todas as mudanÃ§as

### RelatÃ³rios TÃ©cnicos
- **`docs/EDA_REPORT.md`**: AnÃ¡lise exploratÃ³ria de dados completa
- **`docs/MODEL_SELECTION.md`**: ComparaÃ§Ã£o de 4 modelos + 3 versÃµes XGBoost
- **`docs/DATA_ARCHITECTURE.md`**: Arquitetura PostgreSQL + Pickle
 
### Arquitetura MVC-ML
- **`src/ml/README.md`**: DocumentaÃ§Ã£o completa da arquitetura modular

---
    
---

## ğŸ”§ ConfiguraÃ§Ãµes Importantes

### `src/ml/models/configs.py`

```python
# HiperparÃ¢metros XGBoost v2.1.0 (Production)
xgboost_params = {
    'colsample_bytree': 0.7,      # 70% features por Ã¡rvore
    'learning_rate': 0.3,          # Taxa de aprendizado alta
    'max_depth': 6,                # Ãrvores profundas (nÃ£o-linear)
    'min_child_weight': 1,         # MÃ­nimo peso folha
    'n_estimators': 100,           # 100 Ã¡rvores
    'scale_pos_weight': 577,       # Compensa desbalanceamento
    'subsample': 0.7,              # 70% amostras por Ã¡rvore
    'eval_metric': 'aucpr'         # PR-AUC como mÃ©trica
}

# Features Removidas (Config-Driven)
excluded_features = [
    'Time',              # Offset temporal sem sentido real
    'Time_Period_of_Day', # Derivada de Time
    'V8', 'V23',         # Baixa correlaÃ§Ã£o (<0.01)
    'Amount',            # Amount_Log Ã© melhor
    'V13'                # Redundante (alta correlaÃ§Ã£o com V17)
]
```

---

## ğŸ“Š MÃ©tricas de Performance

### Pipeline de Tratamento de Dados (52% mais rÃ¡pido âš¡)

| Step | Antes | Depois | Ganho | OtimizaÃ§Ã£o |
|------|-------|--------|-------|------------|
| **04 Normalize** | 90s | 16.5s | **81.6%** ğŸ”¥ | PostgreSQL COPY |
| **02+03 Parallel** | 4.8s | 3.9s | **18.6%** âš¡ | ThreadPoolExecutor |
| **Pipeline Total** | ~130s | **~62s** | **52%** ğŸš€ | Multi-otimizaÃ§Ã£o |

### Modelos XGBoost (Test Set)

| MÃ©trica | v1.1.0 | v2.0.0 | v2.1.0 â­ |
|---------|--------|--------|----------|
| **PR-AUC** | 0.8719 | 0.8847 | 0.8772 |
| **ROC-AUC** | 0.9738 | 0.9801 | 0.9765 |
| **Precision** | 72.27% | 85.42% | **86.60%** |
| **Recall** | 87.76% | 83.67% | 81.63% |
| **F1-Score** | 79.26% | 84.54% | 84.04% |
| **True Positives** | 86 | 82 | 80 |
| **False Positives** | 33 | 14 | **13** |
| **False Negatives** | 12 | 16 | 18 |
| **True Negatives** | 56,831 | 56,850 | 56,851 |

---

## ğŸš§ PrÃ³ximos Passos (Opcional)
- [ ] **SHAP Analysis**: Explicabilidade de prediÃ§Ãµes individuais
- [ ] **Kafka Streaming**: Real-time fraud detection (ver `docs/plan_kafka.md`)
- [ ] **Dashboard Flask**: Interface web para inferÃªncia interativa
- [ ] **Docker Full Stack**: Container com PostgreSQL + Flask + ML
- [ ] **CI/CD Pipeline**: GitHub Actions para testes + deploy automÃ¡tico

---

## ğŸ“– ReferÃªncias

- **Dataset**: [Kaggle - Credit Card Fraud Detection](https://www.kaggle.com/mlg-ulb/creditcardfraud)
- **XGBoost**: Chen & Guestrin (2016) - "XGBoost: A Scalable Tree Boosting System"
- **PR-AUC**: Saito & Rehmsmeier (2015) - "The Precision-Recall Plot Is More Informative"
- **RobustScaler**: Scikit-learn - NormalizaÃ§Ã£o resistente a outliers (mediana + IQR)
- **PostgreSQL COPY**: PostgreSQL Documentation - Bulk loading optimization

---

## ğŸ‘¥ Autores
- Victor Lucas Santos de Oliveira
- Adrianny Lelis da Silva

--- 


## ğŸ“Š Treinamento de Modelos
  
## 4. EDA (AnÃ¡lise ExploratÃ³ria)
```bash
# GrÃ¡ficos gerados em docs/images/
ls docs/images/*.png
```

---

## ğŸ“ Estrutura do Projeto

```
ml-fraud-detector/
â”œâ”€â”€ main.py                      # ğŸ¯ CLI principal (pipeline/train/tune/predict)
â”œâ”€â”€ pyproject.toml               # ConfiguraÃ§Ã£o do projeto (uv/pip)
â”œâ”€â”€ requirements.txt             # DependÃªncias Python
â”œâ”€â”€ README.md                    # Este arquivo
â”‚
â”œâ”€â”€ data/                        # ğŸ“Š Datasets e configuraÃ§Ãµes
â”‚   â”œâ”€â”€ creditcard.csv           # Dataset original (284,807 transaÃ§Ãµes)
â”‚   â”œâ”€â”€ xgboost_hyperparameters.json  # HiperparÃ¢metros ativos
â”‚   â”œâ”€â”€ archive/                 # VersÃµes antigas de hiperparÃ¢metros
â”‚   â””â”€â”€ examples/                # Exemplos de transaÃ§Ãµes para teste
â”‚       â”œâ”€â”€ fraud_transaction.json
â”‚       â””â”€â”€ legitimate_transaction.json
â”‚
â”œâ”€â”€ models/                      # ğŸ¤– Modelos treinados
â”‚   â”œâ”€â”€ scalers.pkl              # RobustScaler + StandardScaler
â”‚   â”œâ”€â”€ xgboost_v2.1.0.pkl       # â­ Modelo em produÃ§Ã£o
â”‚   â””â”€â”€ archive/                 # VersÃµes antigas de modelos
â”‚
â”œâ”€â”€ reports/                     # ğŸ“ˆ RelatÃ³rios gerados (JSON)
â”‚   â””â”€â”€ feature_selection_report.json
â”‚
â”œâ”€â”€ database/                    # ğŸ—„ï¸ ConfiguraÃ§Ã£o PostgreSQL
â”‚   â”œâ”€â”€ docker-compose.yml       # Docker setup (PostgreSQL 15)
â”‚   â””â”€â”€ schema.sql               # Schema completo (7 tabelas pipeline + 3 metadata)
â”‚
â”œâ”€â”€ docs/                        # ğŸ“š DocumentaÃ§Ã£o tÃ©cnica
â”‚   â”œâ”€â”€ EDA_REPORT.md            # AnÃ¡lise exploratÃ³ria
â”‚   â”œâ”€â”€ MODEL_SELECTION.md       # ComparaÃ§Ã£o de 4 modelos
â”‚   â”œâ”€â”€ DATA_ARCHITECTURE.md     # Arquitetura PostgreSQL + Pickle
â”‚   â”œâ”€â”€ DECISOES_TECNICAS.md     # DecisÃµes ML + otimizaÃ§Ãµes
â”‚   â”œâ”€â”€ TRANSACTION_EXAMPLES.md  # Exemplos prÃ¡ticos de transaÃ§Ãµes (fraude vs legÃ­tima)
â”‚   â””â”€â”€ images/                  # GrÃ¡ficos EDA
â”‚       â”œâ”€â”€ 01_class_distribution.png
â”‚       â”œâ”€â”€ 02_amount_analysis.png
â”‚       â”œâ”€â”€ 03_correlation_heatmap.png
â”‚       â””â”€â”€ ...
â”‚
â””â”€â”€ src/                         # ğŸ’» CÃ³digo fonte
    â”œâ”€â”€ __init__.py
    â”‚
    â”œâ”€â”€ ml/                      # ğŸ§  Machine Learning
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ README.md            # DocumentaÃ§Ã£o da arquitetura MVC-ML
    â”‚   â”‚
    â”‚   â”œâ”€â”€ processing/          # ğŸ”§ FunÃ§Ãµes de processamento
    â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â”œâ”€â”€ loader.py        # PostgreSQL COPY (otimizado 81.6%)
    â”‚   â”‚   â”œâ”€â”€ validation.py    # Schema e integridade
    â”‚   â”‚   â”œâ”€â”€ cleaning.py      # AnÃ¡lise de outliers
    â”‚   â”‚   â”œâ”€â”€ normalization.py # RobustScaler + StandardScaler
    â”‚   â”‚   â”œâ”€â”€ feature_engineering.py  # 9 novas features
    â”‚   â”‚   â”œâ”€â”€ feature_selection.py    # AnÃ¡lise automatizada
    â”‚   â”‚   â”œâ”€â”€ splitters.py     # Stratified train/test split
    â”‚   â”‚   â””â”€â”€ metadata.py      # Pipeline metadata tracking
    â”‚   â”‚
    â”‚   â”œâ”€â”€ pipelines/           # ğŸš€ OrquestraÃ§Ã£o
    â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â””â”€â”€ data_pipeline.py # Steps 01-07 (completo)
    â”‚   â”‚
    â”‚   â”œâ”€â”€ training/            # ğŸ“ Treinamento ML
    â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â”œâ”€â”€ train.py         # Treino com JSON configs
    â”‚   â”‚   â””â”€â”€ tune.py          # Grid Search + auto-update JSON
    â”‚   â”‚
    â”‚   â””â”€â”€ models/              # âš™ï¸ ConfiguraÃ§Ãµes
    â”‚       â”œâ”€â”€ __init__.py
    â”‚       â””â”€â”€ configs.py       # Dataclasses + carregamento JSON
    â”‚
    â”œâ”€â”€ models/                  # ğŸ“¦ Data models
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â””â”€â”€ database_models.py   # SQLAlchemy models
    â”‚
    â””â”€â”€ services/                # ğŸ”Œ ServiÃ§os
        â””â”€â”€ database/            # ğŸ—„ï¸ ConexÃ£o PostgreSQL
            â”œâ”€â”€ __init__.py
            â””â”€â”€ connection.py    # Engine + connection pooling
```

---

## ğŸ”„ Pipeline de Tratamento de Dados (Modular)

Cada step Ã© **isolado e reutilizÃ¡vel**, podendo ser orquestrado como **DAG no Airflow**:

### âœ… Step 01: Load Raw Data
- **Input**: `data/creditcard.csv`
- **Output**: PostgreSQL `raw_transactions` (284,807 linhas)
- **FunÃ§Ã£o**: Carregar e validar schema

### âœ… Step 02: Remove Outliers
- **Input**: `raw_transactions`
- **Output**: `cleaned_transactions` (284,804 linhas)
- **FunÃ§Ã£o**: Remover Amount > $15k (3 transaÃ§Ãµes, todas legÃ­timas)
- **Justificativa**: 73.6% das fraudes tÃªm Amount < $100 (mediana: $9.25)

### âœ… Step 03: Handle Missing Values
- **Input**: `cleaned_transactions`
- **Output**: `imputed_transactions`
- **FunÃ§Ã£o**: ImputaÃ§Ã£o (mediana) ou remoÃ§Ã£o (Class)

### âœ… Step 04: Normalize Features 
- **Input**: `imputed_transactions`
- **Output**: `normalized_transactions` + `models/scalers.pkl`
- **FunÃ§Ã£o**: RobustScaler (Amount), StandardScaler (Time)

### âœ… Step 05: Feature Engineering 
- **Input**: `normalized_transactions`
- **Output**: `engineered_transactions`
- **FunÃ§Ã£o**: Time_Period, Amount_Bin, Amount_Log, V_Interactions

### âœ… Step 06: Train/Test Split
- **Input**: `engineered_transactions`
- **Output**: `train_features`, `test_features`, `train_target`, `test_target`
- **FunÃ§Ã£o**: StratifiedShuffleSplit (80/20)

ğŸ“š **DocumentaÃ§Ã£o completa**: [`src/ml/README.md`](src/ml/README.md)

---
## ğŸ¤– Modelos de Machine Learning

**RelatÃ³rio Completo**: [`docs/MODEL_SELECTION.md`](docs/MODEL_SELECTION.md) - AnÃ¡lise comparativa completa de 4 algoritmos + 3 versÃµes XGBoost

### Abordagem Testada: ComparaÃ§Ã£o de 4 Algoritmos
- âœ… **XGBoost v2.1.0** (â­ **RECOMENDADO**): PR-AUC 0.8772, Precision 86.60%, 13 FP
- âœ… **XGBoost v2.0.0** (Grid Search): PR-AUC 0.8847, Precision 85.42%, 14 FP  
- âœ… **XGBoost v1.1.0** (Baseline): PR-AUC 0.8719, Precision 72.27%, 33 FP
- âŒ **Decision Tree**: PR-AUC 0.7680, Precision 24.24%, 250 FP (rejeitado)
- âŒ **LightGBM**: PR-AUC 0.0372, Precision 3.36%, 2,475 FP (falha catastrÃ³fica)
- âŒ **SVM RBF**: PR-AUC 0.5326, Precision 19.50%, 339 FP (muito lento: 15 min)
---

## ğŸ“Š AnÃ¡lise ExploratÃ³ria (EDA)
### Insights Principais

**Desbalanceamento**:
- Fraudes: 492 (0.172%)
- LegÃ­timas: 284.315 (99.828%)
- Ratio: 1:578

**Amount (Valores)**:
- Fraudes: Mediana $9.25, MÃ©dia $122.21
- 73.6% das fraudes tÃªm Amount < $100
- Nenhuma fraude tem Amount > $15k

**CorrelaÃ§Ãµes (Top 3)**:
- V17: -0.326 (mais forte!)
- V14: -0.302
- V12: -0.261

**Temporal**:
- Fraudes concentradas em certos horÃ¡rios
- Taxa de fraude varia 10x ao longo do dia

ğŸ“Š **GrÃ¡ficos**: `docs/images/*.png`  
ğŸ“‹ **RelatÃ³rio Completo**: [`docs/EDA_REPORT.md`](docs/EDA_REPORT.md) - AnÃ¡lise detalhada com decisÃµes tÃ©cnicas e justificativas

---

## ğŸ—„ï¸ PostgreSQL Schema

```sql
-- Tabelas do Pipeline
raw_transactions         (284,807 linhas) - CSV original
cleaned_transactions     (284,804 linhas) - Sem outliers
imputed_transactions     (284,804 linhas) - Sem missing
normalized_transactions  (284,804 linhas) - Features normalizadas
engineered_transactions  (284,804 linhas) - Features novas
train_features          (~227,843 linhas) - 80% treino
test_features           (~56,961 linhas)  - 20% teste

-- Tabelas de Metadados
metrics_history          - MÃ©tricas de modelos ao longo do tempo
trained_models           - Registro de modelos treinados
data_splits              - HistÃ³rico de splits train/test
```

---

## ğŸ¯ Status do Projeto

### âœ… ConcluÃ­do
- [x] Setup PostgreSQL (Docker Compose)
- [x] ConexÃ£o SQLAlchemy testada
- [x] EDA completo com OOP (5 classes)
- [x] Pipeline Step 01: Load Raw Data
- [x] Pipeline Step 02: Remove Outliers
- [x] Pipeline Step 03: Handle Missing Values
- [x] DocumentaÃ§Ã£o (plan_main.md, plan_kafka.md, changelog.md)

### ğŸ”„ Em Progresso
- [ ] RevisÃ£o do codigo

### ğŸ“‹ PrÃ³ximos Passos
- [ ] Dashboard Flask
- [ ] Kafka Streaming (opcional)
- [ ] VÃ­deo explicativo

---

## ğŸ“š DocumentaÃ§Ã£o

- **[Plan Main](docs/plan_main.md)**: Plano completo do MVP
- **[Plan Kafka](docs/plan_kafka.md)**: Enhancement com streaming (opcional)
- **[Changelog](docs/changelog.md)**: Registro de mudanÃ§as
- **[DecisÃµes TÃ©cnicas](docs/DECISOES_TECNICAS.md)**: Justificativas metodolÃ³gicas
- **[Pipeline README](src/data_processing/README.md)**: DocumentaÃ§Ã£o do pipeline

---

## ğŸ”— ReferÃªncias

- **Dataset**: [Kaggle - Credit Card Fraud Detection](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)
- **Airflow**: https://airflow.apache.org/
- **Scikit-learn**: https://scikit-learn.org/
- **XGBoost**: https://xgboost.readthedocs.io/
- **PostgreSQL**: https://www.postgresql.org/

---

## ğŸ‘¥ Autores

**Victor Lucas Santos de Oliveira** - [LinkedIn](https://www.linkedin.com/in/vlso/)

**Adrianny Lelis da Silva** - [LinkedIn](https://www.linkedin.com/in/adriannylelis/)

---
  