# ğŸš¨ Credit Card Fraud Detection System

![Machine Learning Fraud Detection System](docs/images/dashboard_screenshot.png)

A complete **Machine Learning fraud detection system** featuring a modular pipeline, PostgreSQL persistence, an interactive CLI, and a **real-time web dashboard**.
Developed as part of the **FIAP Tech Challenge â€“ Phase 3**.

---

## ğŸš€ Quick Demo

**Want to see it in action?** Run the dashboard in just 3 steps:

```bash
# 1. Start the Flask server
python run.py

# 2. Open in your browser
# http://127.0.0.1:5000

# 3. Test the detector!
#    â†’ Click â€œLEGÃTIMAâ€ or â€œFRAUDULENTAâ€
#    â†’ Click â€œEXECUTAR SIMULAÃ‡ÃƒOâ€
#    â†’ Watch real-time results:
#       âœ… Model Prediction (classified by XGBoost)
#       ğŸ¯ Ground Truth (actual transaction type)
#       ğŸ“Š Fraud probability (0â€“100%)
#       ğŸ” Confidence level (HIGH / MODERATE / LOW)
#       âš¡ Inference latency (measured in real-time)
```

**ğŸ¯ What youâ€™ll see:**

* **Simulation Panel** â€“ trigger legitimate or fraudulent transactions in one click
* **Real-Time Stats** â€“ total transactions, detected frauds, recall rate, latency
* **Full History** â€“ all classifications with prediction vs actual label

> ğŸ’¡ **Tip:** Try simulating multiple fraudulent transactions. The model will realistically miss some (~15% error), demonstrating that itâ€™s **not overfitted**.

---

## ğŸ¯ Objective

Develop a fraud detection system using an **optimized XGBoost** model with:

* âœ… Handling of **highly imbalanced data** (1:578 fraud ratio)
* âœ… Modular **MVC-ML Pipeline** (processing â†’ training â†’ inference)
* âœ… Robust validation with **StratifiedKFold**
* âœ… **Automated Grid Search** with hyperparameter versioning
* âœ… **PostgreSQL** (data) + **Pickle** (models) persistence
* âœ… **Complete CLI** with 4 operational modes
* âœ… **Flask REST API** backend for real-time simulation
* âœ… **Interactive Web Dashboard** for live monitoring and insights

---

## ğŸ—ï¸ Project Architecture

### Modular MVC-ML + Service Layer

The system follows a **layered modular architecture** for clear separation of concerns:

* **Model (M)**: `src/models/` â€“ SQLAlchemy ORM + ML configs
* **View (V)**: `src/services/frontend/` â€“ HTML templates + static assets
* **Controller (C)**: `src/services/backend/` â€“ Flask routes + logic
* **ML Pipeline**: `src/ml/` â€“ data processing and training
* **Services**: `src/services/` â€“ infrastructure components (DB, ML, Frontend, Backend)

```
ml-fraud-detector/
â”œâ”€â”€ data/                        # ğŸ“Š Datasets and configs
â”‚   â”œâ”€â”€ archive/                 # Older hyperparameter versions
â”‚   â”œâ”€â”€ examples/                # Sample transactions
â”‚   â”œâ”€â”€ creditcard.csv           # Original dataset (284,807 rows)
â”‚   â””â”€â”€ xgboost_hyperparameters.json
â”‚
â”œâ”€â”€ database/                    # ğŸ—„ï¸ PostgreSQL config
â”‚   â”œâ”€â”€ migrations/              # SQL migrations
â”‚   â”œâ”€â”€ docker-compose.yml       # PostgreSQL 15 setup
â”‚   â””â”€â”€ schema.sql               # Schema (7 pipeline + 2 webapp tables)
â”‚
â”œâ”€â”€ docs/                        # ğŸ“š Documentation
â”‚   â”œâ”€â”€ images/                  # Charts and screenshots
â”‚   â”œâ”€â”€ API_ENDPOINTS.md         # REST API docs
â”‚   â”œâ”€â”€ DATA_ARCHITECTURE.md     # PostgreSQL + Pickle architecture
â”‚   â”œâ”€â”€ DECISOES_TECNICAS.md     # ML optimizations
â”‚   â”œâ”€â”€ EDA_REPORT.md            # Exploratory data analysis
â”‚   â”œâ”€â”€ MODEL_SELECTION.md       # Model comparison
â”‚   â””â”€â”€ TRANSACTION_EXAMPLES.md  # Examples
â”‚
â”œâ”€â”€ models/                      # ğŸ¤– Trained ML models
â”‚   â”œâ”€â”€ archive/                 # Older versions
â”‚   â”œâ”€â”€ scalers.pkl              # RobustScaler + StandardScaler
â”‚   â””â”€â”€ xgboost_v2.1.0.pkl       # â­ Production model
â”‚
â”œâ”€â”€ reports/                     # ğŸ“ˆ Generated analysis
â”‚   â””â”€â”€ feature_selection_analysis.json
â”‚
â”œâ”€â”€ src/                         # ğŸ’» Source code
â”‚   â”œâ”€â”€ ml/                      # ğŸ§  ML pipeline
â”‚   â”œâ”€â”€ models/                  # ğŸ“¦ SQLAlchemy ORM models
â”‚   â”œâ”€â”€ services/                # ğŸ”Œ Service layer
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ main.py                      # ğŸ¯ CLI entry point
â”œâ”€â”€ run.py                       # ğŸš€ Flask app entry
â”œâ”€â”€ requirements.txt              # Dependencies
â””â”€â”€ README.md
```

---

### Data Processing Pipeline (7 Steps)

```
CSV (raw) â†’ [01] Load â†’ [02] Outlier Analysis â†’ [03] Missing Values
         â†’ [04] Normalize â†’ [05] Feature Engineering â†’ [06] Feature Selection
         â†’ [07] Train/Test Split â†’ âœ… Ready for training
```

---

### Persistence Architecture

**PostgreSQL Tables**

* `raw_transactions`, `cleaned_transactions`, â€¦ `test_features`
* `classification_results`, `simulated_transactions`

**Pickle Files**

* `models/scalers.pkl` â€“ RobustScaler + StandardScaler
* `models/xgboost_v2.1.0.pkl` â€“ production model

**JSON Configs**

* `xgboost_hyperparameters.json` â€“ active hyperparameters
* `archive/` â€“ previous versions (auto-timestamped)

**Hybrid Design Rationale**

* **PostgreSQL** â†’ traceability + analytics
* **Pickle** â†’ fast model loading
* **JSON** â†’ version control for reproducibility

---

### Technology Stack

* **Python 3.13**, **Pandas**, **XGBoost 3.0.5**
* **Flask 3.0.3**, **SQLAlchemy**, **PostgreSQL 15**
* **Docker Compose**, **ThreadPoolExecutor**, **COPY optimization**

---

## ğŸ“Š Dataset

* **Source:** [Kaggle â€“ Credit Card Fraud Detection](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)
* **Transactions:** 284,807 (2 days, September 2013)
* **Features:** 30 (PCA-transformed + Time, Amount)
* **Target:** Class (0=legit, 1=fraud)
* **Imbalance:** 492 frauds (0.172%) vs 284,315 legitimate

---

## ğŸš€ Quick Start

### 1. Requirements

* Python â‰¥3.13
* PostgreSQL â‰¥15
* 2GB+ RAM

### 2. Installation

```bash
git clone <repo-url>
cd ml-fraud-detector
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

or faster:

```bash
uv pip install -e .
```

### 3. Setup PostgreSQL

**Option A: Docker (recommended)**

```bash
cd database
docker-compose up -d
```

**Option B: Local setup**

```bash
createdb fraud_detection
createuser fraud_user --password fraud_pass_dev
psql -U fraud_user -d fraud_detection -f database/schema.sql
```

### 4. Run the Pipeline

```bash
python main.py pipeline
```

---

## ğŸ–¥ï¸ CLI Interface (`main.py`)

Supports 4 main modes:

### 1ï¸âƒ£ `pipeline`

Runs full data processing pipeline (Steps 01â€“07).

### 2ï¸âƒ£ `train`

Trains XGBoost with current JSON hyperparameters.

### 3ï¸âƒ£ `tune`

Performs automated Grid Search and updates JSON.

### 4ï¸âƒ£ `predict`

Runs inference on CSV or JSON input.

---

## ğŸŒ Flask REST API

### Endpoints

| Method | Endpoint        | Description                         |
| ------ | --------------- | ----------------------------------- |
| `POST` | `/api/simulate` | Generate and classify a transaction |
| `GET`  | `/api/stats`    | Get aggregated stats                |
| `GET`  | `/api/history`  | Retrieve prediction history         |
| `GET`  | `/health`       | Health check                        |

Full API reference: [`docs/API_ENDPOINTS.md`](docs/API_ENDPOINTS.md)

---

## ğŸ¨ Web Dashboard

Interactive web dashboard for simulation and monitoring:

* Run real-time simulations
* Track recall, latency, and fraud rate
* Review full prediction history

---

## ğŸ“š Documentation

* **Technical Reports:** EDA, model selection, and data architecture
* **Plans:** MVP roadmap, Kafka scalability, changelog
* **Architecture Docs:** `src/ml/README.md`

---

## ğŸ”§ Key Configs

`src/ml/models/configs.py`:

```python
xgboost_params = {
    'colsample_bytree': 0.7,
    'learning_rate': 0.3,
    'max_depth': 6,
    'min_child_weight': 1,
    'n_estimators': 100,
    'scale_pos_weight': 577,
    'subsample': 0.7,
    'eval_metric': 'aucpr'
}
```

---

## ğŸ“Š Performance Metrics

### Pipeline Optimizations (52% faster âš¡)

| Step           | Before | After | Gain   | Optimization    |
| -------------- | ------ | ----- | ------ | --------------- |
| Normalize      | 90s    | 16.5s | +81.6% | PostgreSQL COPY |
| Pipeline Total | 130s   | 62s   | +52%   | Parallelization |

### XGBoost Results

| Metric    | v1.1.0 | v2.0.0 | v2.1.0 â­   |
| --------- | ------ | ------ | ---------- |
| PR-AUC    | 0.8719 | 0.8847 | **0.8772**     |
| Precision | 72.27% | 85.42% | 86.60% |
| Recall    | 87.76% | 83.67% | 81.63%     |
| F1-Score  | 79.26% | 84.54% | 84.04%     |

---

## ğŸ—„ï¸ PostgreSQL Schema

Includes:

* Pipeline tables (raw â†’ processed)
* Webapp tables (`classification_results`, `simulated_transactions`) 

---

## ğŸš€ Status

âœ… Completed
ğŸ“‹ Next Step: Optional Kafka streaming for scalability
 
## ğŸ”„ Future Scalability

The modular ML pipeline architecture is designed for easy **Apache Airflow integration**:

* **Step-based structure** (01-07) maps directly to Airflow DAGs
* **Service layer separation** enables distributed task execution  
* **JSON configs + PostgreSQL** provide stateful orchestration support
* **CLI modes** (`train`, `tune`, `pipeline`) can become Airflow operators

This allows seamless migration from local execution to **scheduled, distributed ML workflows** without code restructuring.

> *In large-scale scenarios, Apache Kafka can enable distributed ingestion, parallel consumers, and real-time reprocessing.*
 
---

## ğŸ”— References

* **Dataset:** [Kaggle â€“ Credit Card Fraud Detection](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)
* **Docs:** [XGBoost](https://xgboost.readthedocs.io/), [Flask](https://flask.palletsprojects.com/), [PostgreSQL](https://www.postgresql.org/)

---

## ğŸ‘¥ Authors

**Victor Lucas Santos de Oliveira** â€“ [LinkedIn](https://www.linkedin.com/in/vlso/)
**Adrianny Lelis da Silva** â€“ [LinkedIn](https://www.linkedin.com/in/adriannylelis/)

--- 