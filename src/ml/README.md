# ğŸ—ï¸ Arquitetura MVC-ML - Fraud Detection System (OTIMIZADO)

## ğŸ“ Estrutura do Projeto

```
src/ml/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ processing/           # FunÃ§Ãµes reutilizÃ¡veis (OTIMIZADAS!)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ loader.py                  # OTIMIZADO: PostgreSQL COPY (81.6% mais rÃ¡pido)
â”‚   â”œâ”€â”€ validation.py              # ValidaÃ§Ã£o de schema e integridade
â”‚   â”œâ”€â”€ cleaning.py                # AnÃ¡lise de outliers (preserva todos os dados)
â”‚   â”œâ”€â”€ normalization.py           # RobustScaler + StandardScaler âœ…
â”‚   â”œâ”€â”€ feature_engineering.py     # 9 novas features (Time_Period, Amount_Bin, etc) âœ…
â”‚   â”œâ”€â”€ feature_selection.py       # AnÃ¡lise automatizada (Pearson, Spearman, MI, VIF) âœ…
â”‚   â”œâ”€â”€ splitters.py               # Stratified train/test split âœ…
â”‚   â””â”€â”€ metadata.py                # Pipeline metadata tracking
â”‚
â”œâ”€â”€ pipelines/            # Scripts que encadeiam funÃ§Ãµes (OTIMIZADOS!)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ data_pipeline.py           # Pipeline completo (Steps 01-07) âœ…
â”‚                                   # - PostgreSQL COPY para bulk inserts
â”‚                                   # - ParalelizaÃ§Ã£o Steps 02-03 (ThreadPoolExecutor)
â”‚                                   # - Metadata-only para steps sem alteraÃ§Ã£o
â”‚                                   # - Feature Selection Analysis (Step 05.5)
â”‚                                   # - Config-driven feature removal (Step 06)
â”‚
â”œâ”€â”€ models/               # ConfiguraÃ§Ãµes, schemas
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ configs.py                 # ConfiguraÃ§Ãµes centralizadas (dataclasses)
â”‚                                   # - Carrega hiperparÃ¢metros de data/xgboost_hyperparameters.json
â”‚                                   # - Define feature selection (excluded_features)
â”‚                                   # - Config-driven approach (sem hardcoded values)
â”‚
â”œâ”€â”€ training/             # Scripts de treinamento
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ train.py                   # Treinamento com hiperparÃ¢metros do JSON
â”‚   â”œâ”€â”€ tune.py                    # Grid Search + atualizaÃ§Ã£o automÃ¡tica de JSON
â”‚   â””â”€â”€ archive/                   # Scripts obsoletos (histÃ³rico)
```

---

## ğŸ¯ PrincÃ­pios da Arquitetura

### 1. **SeparaÃ§Ã£o de Responsabilidades**
- **Processing**: FunÃ§Ãµes puras, reutilizÃ¡veis, testÃ¡veis
- **Pipelines**: Encadeiam funÃ§Ãµes de processing
- **Models**: ConfiguraÃ§Ãµes e schemas (carrega de JSON)
- **Training**: Treino e otimizaÃ§Ã£o de modelos
- **Validators**: [FUTURO] MÃ©tricas ML

### 2. **Modularidade**
- Cada funÃ§Ã£o em `processing/` faz UMA coisa
- FÃ¡cil de testar isoladamente
- FÃ¡cil de compor em pipelines diferentes

### 3. **ConfiguraÃ§Ã£o Centralizada + JSON Versionado**
- HiperparÃ¢metros em `data/xgboost_hyperparameters.json` (versionado)
- Feature selection em `models/configs.py` (hardcoded mas documentado)
- Dataclasses tipadas para type safety
- FÃ¡cil de modificar sem alterar cÃ³digo
- Archive automÃ¡tico de versÃµes antigas (`data/archive/`)

### 4. **IdempotÃªncia**
- Cada step do pipeline pode ser re-executado
- Sem efeitos colaterais
- Tabelas PostgreSQL sempre recriadas

### 5. **Production-Ready**
- Nenhum valor hardcoded em comparaÃ§Ãµes
- Baselines dinÃ¢micas carregadas de `data/archive/`
- Versionamento automÃ¡tico de modelos e hiperparÃ¢metros
- Sistema escalÃ¡vel para qualquer nÃºmero de versÃµes

### 5. **Performance Otimizada** âš¡
- PostgreSQL COPY para bulk inserts (70-80% mais rÃ¡pido)
- ParalelizaÃ§Ã£o de steps independentes (ThreadPoolExecutor)
- Metadata tracking evita duplicaÃ§Ã£o de dados
- Pipeline completo: **~62s** (antes: ~130s) - **52% mais rÃ¡pido!**

---

## ğŸš€ Como Usar

### Executar Pipeline Completo
```bash  
# Via pipeline direto
python -m src.ml.pipelines.data_pipeline
```

### Importar FunÃ§Ãµes em Scripts
```python
# Carregar dados (OTIMIZADO com COPY!)
from src.ml.processing.loader import load_from_postgresql, save_to_postgresql

# Normalizar (RobustScaler para outliers)
from src.ml.processing.normalization import fit_and_transform_features

# Feature engineering (9 novas features)
from src.ml.processing.feature_engineering import engineer_all_features

# Train/test split estratificado
from src.ml.processing.splitters import stratified_train_test_split

# Usar configuraÃ§Ãµes
from src.ml.models.configs import config
print(config.database.connection_string)
```

---

## ğŸ“Š Pipeline de Dados (7 Steps) - COMPLETO âœ…

### Step 01: Load Raw Data âœ…
- **Entrada**: `data/creditcard.csv`
- **SaÃ­da**: PostgreSQL `raw_transactions` (284,807 linhas)
- **FunÃ§Ã£o**: `processing/loader.py::load_csv_to_dataframe()` + `save_to_postgresql()`
- **Performance**: ~20s (com PostgreSQL COPY otimizado)

### Step 02: Outlier Analysis âœ…
- **Entrada**: `raw_transactions`
- **SaÃ­da**: **Metadata apenas** (dados NÃƒO duplicados!)
- **FunÃ§Ã£o**: `processing/cleaning.py::identify_outliers()`
- **DecisÃ£o**: Preservar 100% dos dados (18.5% fraudes em outliers)
- **Performance**: ~2.4s
- **ParalelizaÃ§Ã£o**: Roda em paralelo com Step 03 âš¡

### Step 03: Handle Missing âœ…
- **Entrada**: `raw_transactions`
- **SaÃ­da**: **Metadata apenas** (dados NÃƒO duplicados!)
- **FunÃ§Ã£o**: `processing/validation.py::validate_no_missing_values()`
- **Resultado**: Nenhum missing value encontrado (dataset 100% completo)
- **Performance**: ~2.4s
- **ParalelizaÃ§Ã£o**: Roda em paralelo com Step 02 âš¡

### Step 04: Normalize âœ…  
- **Entrada**: `raw_transactions`
- **SaÃ­da**: `normalized_transactions` + `models/scalers.pkl`
- **FunÃ§Ã£o**: `processing/normalization.py::fit_and_transform_features()`
- **Scalers**: RobustScaler (Amount), StandardScaler (Time)
- **Performance**: ~16.5s (ANTES: ~90s) - **81.6% mais rÃ¡pido!** ğŸ”¥
- **OtimizaÃ§Ã£o**: PostgreSQL COPY em vez de to_sql()
- **Versionamento**: `models/scalers_v1.0.0.pkl` (opcional)

### Step 05: Feature Engineering âœ…
- **Entrada**: `normalized_transactions`
- **SaÃ­da**: `engineered_transactions` (284,807 Ã— 40 colunas)
- **FunÃ§Ã£o**: `processing/feature_engineering.py::engineer_all_features()`
- **Features**: Time_Period, Amount_Log, Amount_Bin, V-statistics (Mean/Std/Min/Max/Range)
- **Performance**: ~20.6s (com PostgreSQL COPY otimizado)

### Step 05.5: Feature Selection Analysis âœ…
- **Entrada**: `engineered_transactions`
- **SaÃ­da**: `reports/feature_selection_analysis.json` (relatÃ³rio JSON)
- **FunÃ§Ã£o**: `processing/feature_selection.py::analyze_feature_importance()`
- **AnÃ¡lises**:
  - Pearson Correlation (linear)
  - Spearman Correlation (monotÃ´nica)
  - Mutual Information (nÃ£o-linear)
  - VIF - Variance Inflation Factor (multicolinearidade)
  - Correlation Matrix (redundÃ¢ncia entre features)
- **Output**: RelatÃ³rio JSON com candidatos a remoÃ§Ã£o
- **Performance**: ~15s
- **AÃ§Ã£o Requerida**: Revisar relatÃ³rio e atualizar `configs.py`

### Step 06: Apply Feature Selection âœ…
- **Entrada**: `engineered_transactions`
- **SaÃ­da**: `selected_features` (SE houver exclusÃµes configuradas)
- **FunÃ§Ã£o**: `processing/feature_selection.py::apply_feature_selection()`
- **Config-Driven**: Remove features listadas em `configs.py::FeatureSelectionConfig.excluded_features`
- **Performance**: ~5s (ou metadata-only se lista vazia)
- **Versionamento**: Incrementar `model_version` quando alterar exclusÃµes

### Step 07: Train/Test Split
- **Entrada**: `selected_features` (se Step 06 aplicou) OU `engineered_transactions`
- **SaÃ­da**: `train_data` (227,845) + `test_data` (56,962)
- **FunÃ§Ã£o**: `processing/splitters.py::stratified_train_test_split()`
- **Split**: 80/20 estratificado (preserva proporÃ§Ã£o 0.172%)
- **Performance**: ~22.2s (com PostgreSQL COPY para ambas tabelas)

---

## ğŸ¯ Feature Selection Strategy (Config-Driven)

### Filosofia: AnÃ¡lise Automatizada + DecisÃ£o Manual

**Por que NÃƒO automatizar completamente?**
- âŒ RemoÃ§Ã£o automÃ¡tica pode descartar features Ãºteis nÃ£o-lineares
- âŒ Contexto de negÃ³cio importa (fraudes de alto valor, padrÃµes temporais)
- âŒ A/B testing manual permite comparar performance

**SoluÃ§Ã£o: Config-Driven Approach**
1. âœ… **Step 05.5**: Analisa automaticamente (Pearson, Spearman, MI, VIF)
2. âœ… **RelatÃ³rio JSON**: Salva candidatos a remoÃ§Ã£o em `reports/feature_selection_analysis.json`
3. âœ… **Desenvolvedor revisa**: Entende por que features tÃªm baixa correlaÃ§Ã£o
4. âœ… **Atualiza configs.py**: Adiciona features Ã  lista `excluded_features`
5. âœ… **Step 06**: Aplica remoÃ§Ã£o automaticamente no prÃ³ximo run

### Workflow de Desenvolvimento

```bash
# 1. Primeira execuÃ§Ã£o: gera relatÃ³rio
python test_pipeline.py  # Executa Steps 01-07 (incluindo 05.5)

# 2. Desenvolvedor revisa relatÃ³rio
cat reports/feature_selection_analysis.json

# Output exemplo:
{
  "candidates_for_removal": {
    "low_correlation_all_methods": ["V13", "V15", "V22"],
    "count": 3,
    "features_detail": {
      "V13": {
        "pearson": 0.0046,
        "spearman": 0.0037,
        "mutual_info": 0.0004
      },
      ...
    }
  },
  "multicollinearity": {
    "high_vif_features": [],
    "redundant_pairs": []
  }
}

# 3. Atualiza configs.py manualmente
vim src/ml/models/configs.py

# Descomentar features para remover:
excluded_features: List[str] = field(default_factory=lambda: [
    'V13',  # Baixa correlaÃ§Ã£o (decisÃ£o: 2025-10-02)
    'V15',  # Baixa correlaÃ§Ã£o (decisÃ£o: 2025-10-02)
    'V22',  # Baixa correlaÃ§Ã£o (decisÃ£o: 2025-10-02)
])

# Incrementar versÃ£o:
model_version: str = "1.1.0"

# 4. Re-executa pipeline
python test_pipeline.py  # Step 06 aplica remoÃ§Ã£o automaticamente

# 5. Treina modelos com features otimizadas
python -m src.ml.pipelines.training_pipeline  # [FUTURO]

# 6. Compara performance (com vs sem feature selection)
# Se melhor: commit configs.py
# Se pior: reverte changes
```

### Vantagens da Abordagem

| Aspecto | Vantagem |
|---------|----------|
| **Rastreabilidade** | Git versiona decisÃµes (`configs.py`) |
| **Reprodutibilidade** | Mesmo cÃ³digo + mesma config = mesmo resultado |
| **A/B Testing** | FÃ¡cil comentar/descomentar features |
| **Context-Aware** | Desenvolvedor considera contexto de negÃ³cio |
| **ProduÃ§Ã£o-Ready** | Config management usado em empresas reais |
| **Educativo** | RelatÃ³rio JSON ensina sobre feature importance |

---

## ğŸ”– Versionamento de Modelos

### Scalers (Pickle)

**MVP/POC (atual)**:
```python
# Simples e eficaz
models/scalers.pkl  # VersÃ£o ativa
```

**ProduÃ§Ã£o (recomendado)**:
```python
# Versionamento explÃ­cito
models/
  scalers_v1.0.0.pkl  # Sem feature selection
  scalers_v1.1.0.pkl  # Com feature selection (V13, V15, V22 removidos)
  scalers_v1.2.0.pkl  # Novas features adicionadas

# Carregar versÃ£o especÃ­fica
scaler_path = config.paths.get_versioned_scaler_path('1.1.0')
scalers = joblib.load(scaler_path)
```

**Enterprise (produÃ§Ã£o real)**:
```python
# MLflow (tracking completo)
import mlflow

with mlflow.start_run():
    mlflow.sklearn.log_model(scaler, "scaler")
    mlflow.log_param("scaler_type", "RobustScaler")
    mlflow.log_param("model_version", "1.1.0")
    mlflow.log_param("excluded_features", ["V13", "V15", "V22"])

# Carregar versÃ£o especÃ­fica
scaler = mlflow.sklearn.load_model("runs:/<run_id>/scaler")
```

### Por que Pickle para Scalers?

| MÃ©todo | PrÃ³s | Contras | Uso |
|--------|------|---------|-----|
| **Pickle** | âœ… Preserva objeto completo<br>âœ… RÃ¡pido (nativo)<br>âœ… IntegraÃ§Ã£o scikit-learn | âŒ Python-only<br>âŒ Sem seguranÃ§a | âœ… **MVP/POC** |
| **ONNX** | âœ… Cross-platform<br>âœ… Otimizado para inferÃªncia | âŒ ConversÃ£o complexa<br>âŒ Nem todos modelos suportados | ProduÃ§Ã£o multi-linguagem |
| **MLflow** | âœ… Versionamento automÃ¡tico<br>âœ… Tracking completo<br>âœ… UI visual | âŒ Infra adicional<br>âŒ Overhead | âœ… **Enterprise** |
| **SQL** | âœ… Centralizado<br>âœ… Backup automÃ¡tico | âŒ Perder mÃ©todos do objeto<br>âŒ Precisa recriar | âŒ NÃ£o recomendado |

**DecisÃ£o para este projeto**: Pickle + versionamento manual (MVP), com path para MLflow documentado para evoluÃ§Ã£o futura.

---

## âš™ï¸ ConfiguraÃ§Ãµes

Todas as configuraÃ§Ãµes estÃ£o em `src/ml/models/configs.py`:

```python
from src.ml.models.configs import config

# Database
config.database.connection_string
config.database.pool_size

# Paths
config.paths.raw_csv
config.paths.scalers_pkl
config.paths.feature_selection_report
config.paths.get_versioned_scaler_path('1.0.0')  # models/scalers_v1.0.0.pkl

# Data
config.data.expected_columns
config.data.target_column
config.data.train_test_split_ratio  # 0.8

# Pipeline
config.pipeline.table_raw
config.pipeline.table_normalized
config.pipeline.table_engineered
config.pipeline.table_selected  # ApÃ³s feature selection
config.pipeline.include_interactions  # False (default)

# Feature Selection (Config-Driven)
config.feature_selection.excluded_features  # Lista para editar manualmente
config.feature_selection.min_pearson_correlation  # 0.01
config.feature_selection.max_vif_threshold  # 10.0
config.feature_selection.model_version  # "1.0.0" (incrementar ao alterar)
```

---

## âš¡ OtimizaÃ§Ãµes Implementadas

### 1. PostgreSQL COPY (81.6% mais rÃ¡pido) ğŸ”¥
```python
# src/ml/processing/loader.py
def save_to_postgresql(df, engine, table_name, use_copy=True):
    """
    Usa PostgreSQL COPY nativo para bulk inserts
    Fallback automÃ¡tico para to_sql() se falhar
    """
    # COPY: ~16s para 284k Ã— 31 colunas
    # to_sql: ~90s para 284k Ã— 31 colunas
```

**Impacto**:
- Step 04: 90s â†’ 16.5s
- Step 05: Beneficiado (40 colunas)
- Step 06: Beneficiado (2 tabelas grandes)

### 2. ParalelizaÃ§Ã£o Steps 02-03 (18.6% mais rÃ¡pido) âš¡
```python
# src/ml/pipelines/data_pipeline.py
with ThreadPoolExecutor(max_workers=2) as executor:
    future_02 = executor.submit(run_step_02_outlier_analysis)
    future_03 = executor.submit(run_step_03_handle_missing)
    # Ambos rodam em paralelo!
```

**Impacto**:
- Antes: 2.43s + 2.36s = 4.79s (sequencial)
- Depois: max(2.43s, 2.36s) = 3.90s (paralelo)

### 3. Metadata-Only (Zero I/O desnecessÃ¡rio)
- Steps 02-03 salvam apenas metadata, NÃƒO duplicam dados
- Rastreabilidade mantida em `pipeline_metadata` table
- Dados permanecem em `raw_transactions`

### 4. Performance Total
| MÃ©trica | Antes | Depois | Ganho |
|---------|-------|--------|-------|
| Step 04 | 90s | 16.5s | **81.6%** ğŸ”¥ |
| Steps 02-03 | 4.8s | 3.9s | **18.6%** âš¡ |
| **Pipeline Completo** | **~130s** | **~62s** | **52%** ğŸš€ |

---

## ğŸ§ª Testes

```bash
# Testar pipeline completo (OTIMIZADO)
python test_pipeline.py

# Testar imports
python -c "from src.ml.pipelines.data_pipeline import DataPipeline; print('OK')"

# Testar funÃ§Ãµes individuais
python -c "from src.ml.processing.loader import save_to_postgresql; print('OK')"
python -c "from src.ml.processing.feature_engineering import engineer_all_features; print('OK')"
```

---

## ğŸ“ˆ PrÃ³ximos Passos

1. âœ… **Pipeline de Dados Completo** (Steps 01-07) - CONCLUÃDO âœ…
2. âœ… **OtimizaÃ§Ãµes de Performance** - CONCLUÃDO âœ…
3. âœ… **Feature Selection Analysis** - CONCLUÃDO âœ…
4. â³ **Training Pipeline** (training/01_train_models.py)
   - Treinar 3 modelos robustos (Decision Tree, SVM, XGBoost)
   - StratifiedKFold validation
   - Grid Search para hiperparÃ¢metros
   - Threshold tuning
4. â³ **Validators** (src/ml/validators/)
   - metrics.py (Precision, Recall, F1, PR-AUC)
   - kfold_validator.py (StratifiedKFold)
   - model_comparator.py (ComparaÃ§Ã£o estatÃ­stica)
5. â³ **Dashboard Flask** (src/views/)
   - Interface interativa
   - SimulaÃ§Ã£o em tempo real
   - WebSocket streaming
6. â³ **[OPCIONAL] Kafka Enhancement** (plan_kafka.md)

---

## ğŸ“š ReferÃªncias

- **MVC Pattern**: Model-View-Controller
- **ML Pipeline**: Modular, testÃ¡vel, reprodutÃ­vel
- **SOLID Principles**: Single Responsibility, Open/Closed
- **PostgreSQL COPY**: Bulk insert nativo (70-80% mais rÃ¡pido)
- **ThreadPoolExecutor**: ParalelizaÃ§Ã£o de tarefas I/O-bound
- **RobustScaler**: NormalizaÃ§Ã£o resistente a outliers (mediana + IQR)

---

**Status Atual**: âœ… **Pipeline de Dados COMPLETO E OTIMIZADO (Steps 01-07)**  
**Performance**: 52% mais rÃ¡pido (~62s vs ~130s)  
**Feature Selection**: Config-driven, Time removido, **38 features** prontas  
**Versionamento**: Scalers com suporte a versionamento (get_versioned_scaler_path)  
**PrÃ³ximo**: â³ **Treinamento de modelos ML em andamento** (Decision Tree, SVM RBF, XGBoost)  

### ğŸ¯ EstratÃ©gia de Modelagem

#### Fase 1: Baseline Training (38 Features) - EM ANDAMENTO â³
- **Features**: V1-V28 (28), Amount/Amount_Log/Amount_Bin (3), Time_Hour/Time_Period_of_Day (2), V-Statistics (5)
- **Time removido**: Apenas offset temporal, sem significado em produÃ§Ã£o
- **3 Modelos Robustos**: Decision Tree, SVM RBF, XGBoost (RegressÃ£o LogÃ­stica REMOVIDA - sensÃ­vel a outliers)
- **ValidaÃ§Ã£o**: StratifiedKFold (k=5)
- **MÃ©tricas**: PR-AUC (principal), Recall, F1, Precision

#### Fase 2: Feature Importance Analysis (PÃ³s-Treino)
- XGBoost fornece `feature_importances_` nativo
- Identificar features com importance â‰ˆ 0
- **DecisÃ£o data-driven**: Remover features inÃºteis baseado em evidÃªncia real
- A/B testing: Comparar performance com/sem features

#### Fase 3: Refinamento (Se NecessÃ¡rio)
- Grid Search para hiperparÃ¢metros (scoring='average_precision')
- Threshold tuning (0.2-0.3 esperado, nÃ£o 0.5)
- Re-treinamento com features otimizadas
- ComparaÃ§Ã£o estatÃ­stica entre modelos

#### Fase 4: Dashboard Flask (MVP)
- Interface interativa
- SimulaÃ§Ã£o em tempo real
- WebSocket streaming
